{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2\n",
    "## Fourier series\n",
    "### Preliminaries: Inner product of functions\n",
    "Assume we have two functions $f(x)$ and $g(x)$, their inneer product $<f(x),g(x)>$ is defined as\n",
    "\n",
    "$$\n",
    "<f(x),g(x)> = \\int_a^b f(x)\\;\\bar{g}(x)\\;\\;dx\n",
    "$$\n",
    "\n",
    "where $\\bar{g}(x)$ is the complex conjugate of $g(x)$. This is the _function_ equivalent of the inner product between two vectors. The inner product of functions projects one onto the other and tells us how much of the first function we can retried in the direction of the second. Seeing this with a vector example is easier. Let's assume we have our two functions, $f(x)$ and $g(x)$, and to establish a connection with the inner product of vectors, let's now assume we sampled them at $\\Delta x$ intervals, let's assume that, if the functions are defined over the interval $[a,b]$ and we sampled $n$ equispaced points in such interval ($\\Delta x = \\frac{b-a}{n-1}$) then we would observe a picture like the following.\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"./figures/hermitianInnerProduct.png\" width=\"600\">\n",
    "</p>\n",
    "\n",
    "We can easily collect all the values for each function in a corresponding vector $\\mathbf{f} = [f_1\\;f_2\\;\\dots\\;f_n]$ (and $\\mathbf{g} = [g_1\\;g_2\\;\\dots\\;g_n]$). Now $\\mathbf{f}$ and $\\mathbf{g}$ are just vectors, so we can compute their inner product as\n",
    "\n",
    "$$\n",
    "<\\mathbf{f},\\mathbf{g}> = \\sum_{i=1}^n f_i \\;\\bar{g}_i = \\sum_{i=1}^n f(x_i)\\;\\bar{g}(x_i)\n",
    "$$\n",
    "\n",
    "In vector terms this is _just_ how much of $\\mathbf{f}$ exists in the direction of $\\mathbf{g}$! Is this the inner product of functions? Almost. There's one kink we need to iron out before the picture is perfect. That kink is the fact that a function has an infinite set of values in any domain where it is defined. Then we should now expect our inner product of functions to be dependent on the number of points $n$ we used to discretise the domain $[a,b]$. Then we have a problem, because the more points we use for the discretisation, the larger the number of addenda in the (vector) inner product, the larger the final result itself. How do we solve this? Well, we can simply _rescale_ by $\\Delta x$\n",
    "\n",
    "$$\n",
    "\\frac{b-a}{n-1} <\\mathbf{f},\\mathbf{g}>=\\sum_{i=1}^n f(x_i)\\;\\bar{g}(x_i)\\;\\Delta x\n",
    "$$\n",
    "\n",
    "which is the Riemann approximation of the continuous function inner product, in fact this summation converges too the function inner product as $n \\rightarrow \\infty$. We can easily verify this with a simple simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "\n",
    "function Dx(a, b, n)\n",
    "    factor = (b - a) / (n - 1)\n",
    "end\n",
    "\n",
    "j = 1;\n",
    "riemannApprox = similar(100.:100.:10000.)\n",
    "for n = 100:100:10000\n",
    "    x = LinRange(-π, π, n)\n",
    "    X = cos.(x)\n",
    "    riemannApprox[j] = Dx(-pi, pi, n) * X' * X\n",
    "    j = j + 1\n",
    "end\n",
    "\n",
    "plot(riemannApprox)\n",
    "hline!(π)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c7a70db9d531d6dd80c25b9f1d2725db6a2644ebf002a6e912882f79f6b1a032"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
